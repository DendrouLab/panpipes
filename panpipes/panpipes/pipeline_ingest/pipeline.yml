# ----------------------- #
# QC pipeline DendrouLab
# ----------------------- #
# written by Charlotte Rich-Griffin, Fabiola Curion

# This pipeline needs a sample metadata file (see resources for an example)
# will run :
#   summary plots of 10x metrics
#   scrublet scores
#   scanpy QC
#   summary QC plots

# Followed by preprocess pipeline. 
# The ingest pipeline does not perform any filtering of cells or genes.
# Filtering happens as the first stpe in the preprocess pipeline. See pipeline_preprocess for details

# Note that if you are combining mutliple datasets from different source the final anndata object will only contain the intersect of the genes
# from all the data sets. For example if the mitochondrial genes have been excluded from one of the inputs, they will be excluded from the final data set.
# In this case it might be wise to run qc separately on each dataset, and them merge them together to create on h5ad file to use as input for
# integration pipeline.
# ------------------------
# compute resource options
# ------------------------
resources:
  # Number of threads used for parallel jobs
  # this must be enough memory to create to load all you input files and once and create the mudatafile
  threads_high: 1
  # this must be enough memory to load your mudata and do computationally light tasks
  threads_medium: 1
  # this must be enough memory to load text files and do plotting, requires much less memory than the other two
  threads_low: 1
# path to conda env, leave blank if running native or your cluster automatically inherits the login node environment
condaenv:

# ------------------------------------------------------------------------------------------------
# Loading and concatenating data options
# ------------------------------------------------------------------------------------------------
# ------------------------
# Project name and data format
# ------------------------
project: "test"
sample_prefix: "test"
# if you have an existing h5mu object that you want to run through the pipeline then
# store it in the folder where you intend to run the folder, and call it
# ${sample_prefix}_unfilt.h5mu where ${sample_prefix} = sample_prefix argument above
use_existing_h5mu: False

# submission_file format:
# For ingest the required columns are
# sample_id  rna_path  rna_filetype  (prot_path  prot_filetype tcr_path  tcr_filetype etc.)
# Example at resources/sample_file_mm.txt
submission_file: 

# which metadata cols from the submission file do you want to include in the anndata object
# as a comma-separated string e.g. batch,disease,sex
metadatacols: 

# which concat join to you want to perform on your mudata objects, recommended inner
# see https://anndata.readthedocs.io/en/latest/concatenation.html#inner-and-outer-joins for details
concat_join_type: inner


#---------------------------------------
# Modalities in the project
#---------------------------------------
# the qc scripts are independent and modalities are processed following this order. Set to True to abilitate modality(ies). 
# Leave empty (None) or False to signal this modality is not in the experiment.

modalities:
  rna: False
  prot: False
  bcr: False
  tcr: False
  atac: False

#---------------------------------------
# Integrating barcode level data e.g. 
# demultiplexing with hashtags, chemical tags or lipid tagging
#---------------------------------------
# if you have cell level metadata such as results from a demultiplexing algorithm, 
# you can incorporate it into the mudata object, 
# this should be stored in one csv containing 2 columns, barcode_id, and sample_id,
# which should match the sample_id column in the submission file.
barcode_mtd:
  include: true
  path:
  metadatacols:  

#---------------------------------------
# Loading adt data - additional options
#---------------------------------------
# As default the ingest will choose the first column of the cellranger features.tsv.gz
# To merge extra information about the antibodies e.g. whether they are hashing antibodies or isotypes,
# Create a table with the first column equivalent to the first column of cellrangers features.tsv.gz
# and specify it below (save as txt file)
protein_metadata_table: 
# Make sure there are unique entries in this column for each adt.
# include a column called isotype (containing True or False) if you want to qc isotypes
# include a column called hashing_ab (containing True or False) if your dataset contains hashing antibodies which you wish to split into a separate modality

# If you want to update the mudata index with a column from protein_metadata_table, specify here
# If there are overlaps with the rna gene symbols, then you might have trouble down the line
# It is recommended to add something to make the labels unique e.g. "adt_CD4"
index_col_choice: 

# If providing separate prot and rna 10X outputs, then the pipeline will load the filtered rna 10X outputs and the raw prot 10X counts
# we assume in most cases that we want to treat filtered rna barcodes as the "real" cells
# and we want out prot assays barcodes to match rna. In which case set subset_prot_barcodes_to_rna: True (which is also the default setting)
# if explicitly set to False, the full prot matrix will be loaded into the mudata obect
load_prot_from_raw: False
subset_prot_barcodes_to_rna: False


# ------------------------------------------------------------------------------------------------
# QC options
# ------------------------------------------------------------------------------------------------
# ------------------------
# 10X qc files processing
# ------------------------
plot_10X_metrics: True 
kneeplot: False
# ------------
## Doublets on GEX - Scrublet
# ------------
scr:
  run: True
  # The values here are the default values, if you were to leave a paramter pblank, it would default to these value,
  expected_doublet_rate: 0.06
  #the expected fraction of transcriptomes that are doublets, typically 0.05-0.1.
  # Results are not particularly sensitive to this parameter")
  sim_doublet_ratio: 2
  # the number of doublets to simulate, relative to the number of observed transcriptomes.
  # Setting too high is computationally expensive. Min tested 0.5
  n_neighbours: 20
  # Number of neighbors used to construct the KNN classifier of observed transcriptomes
  # and simulated doublets.
  # The default value of round(0.5*sqrt(n_cells)) generally works well.
  min_counts: 2
  # Used for gene filtering prior to PCA. Genes expressed at fewer than `min_counts` in fewer than `min_cells` (see below) are excluded"
  min_cells: 3
  # Used for gene filtering prior to PCA.
  # Genes expressed at fewer than `min_counts` (see above) in fewer than `min_cells` are excluded.")
  min_gene_variability_pctl: 85
  # Used for gene filtering prior to PCA. Keep the most highly variable genes
    # (in the top min_gene_variability_pctl percentile),
    #as measured by the v-statistic [Klein et al., Cell 2015]")
  n_prin_comps: 30
  # Number of principal components used to embed the transcriptomes
  # prior to k-nearest-neighbor graph construction
  use_thr: True
  # use a user defined thr to define min doublet score to split true from false doublets?
  # if false just use what the software produces
  # this threshold applies to plots, a=no actual fitlering takes place.
  call_doublets_thr: 0.25
  #if use_thr is True, this thr will be used to define doublets

# ------------
# GEX QC
# ------------
# this part of the pipeline allows to generate the QC parameters that will be used to 
# evaluate inclusion/ exclusion criteria. Filtering of cells/genes happens in the following pipeline
# pipeline_integration.py.

# leave options blank to avoid running, "default" (the data stored within the package) 
# cell cycle action
# ccgenes will plot the proportions of cell cycle genes (recommended to leave as default)
ccgenes: default
# It's often practical to rely on known gene lists, for a series of tasks, like evaluating % of mitochondrial genes or
# ribosomal genes, or excluding IGG genes from HVG selection. We collect useful gene lists in a file, resources/custom_gene_lists_v1.tsv, 
# and define "actions" on them as follows:
# (for pipeline_ingest.py)
# calc_proportions: calculate proportion of reads mapping to X genes over total number of reads, per cell
# score_genes: using scanpy.score_genes function, 
# (for pipeline_integration.py)
# exclude: exclude these genes from the HVG selection, if they are deemed HV.
# plot_markers: plot these genes
# 
# custom genes actions

custom_genes_file: resources/qc_genelist_1.0.csv
calc_proportions: hb,mt,rp
score_genes: MarkersNeutro


# Plot RNA QC metrics
# ------------
# all metrics should be inputted as a comma separated string e.g. a,b,c

# likely a combination of metadatacolumns and demultiplex_metadatacols
plotqc_grouping_var: sample_id
plotqc_rna_metrics: doublet_scores,pct_counts_mt,pct_counts_rp,pct_counts_hb,pct_counts_ig



# ------------
# ADT qc - requires prot_path to be included in the submission file
# ------------
# all metrics should be inputted as a comma separated string e.g. a,b,c

###  ADT QC metrics:
# as standard the following metrics are calculated for prot data
# per cell metrics:
# total_counts,log1p_total_counts,n_adt_by_counts,log1p_n_adt_by_counts
# if isotypes can be detected then the following are calculated also:
# total_counts_isotype,pct_counts_isotype
# choose which ones you want to plot here
plotqc_prot_metrics: total_counts,log1p_total_counts,n_adt_by_counts,pct_counts_isotype

# per antibody metrics
# n_cells_by_counts,mean_counts,log1p_mean_counts,pct_dropout_by_counts,total_counts,log1p_total_counts
# choose which ones you want to plot here:
prot_metrics_per_adt: total_counts,log1p_total_counts,n_cells_by_counts,mean_counts

# isotype outliers: one way to determine which cells are very sticky is to work out which cells have the most isotype UMIs
# associated to them, to label a cell as an isotype outlier, it must meet or exceed the following crietria:
# be in the above x% quantile by UMI counts, for at least n isotypes 
# (e.g. above 90% quantile UMIs in at least 2 isotypes)
identify_isotype_outliers: True
isotype_upper_quantile: 90
isotype_n_pass: 2
# TODO: work out how to plot this.

### Investigate per channel antibody staining:
# This can help determine any inconsistencies in staining per channel and other QC concerns.
# If you want to run clr normalsiation on a per channel basis, then you need to 
# specify which column in your submission file corresponds to the channel
# at the QC stage it can be useful to look at the normalised data on a per channel basis 
# i.e. the 10X channel. 
# this is usually the sample_id column (otherwise leave the next parameter blank)
channel_col: sample_id
# It is important to note that in ingest the per channel normalised adt scores are not saved in the mudata object
#  this is because if you perform feature normalisation (clr normalisation margin 0 or dsb normalisation), 
#  on subsets of cells then the normalised values cannot be simply concatenated. 
# The ADT normalisation is rerun pn the complete object in the preprocess pipeline 
# (or you can run this pipeline with channel_col set as None)
# it is important to note, if you choose to run the clr on a per channel basis, then it is not stored in the h5mu file.
# if you want to save the per channel normalised values set the following to True:
save_norm_prot_mtx: False

# comma separated string of normalisation options
# options: dsb,clr 
# more details in this vignette https://muon.readthedocs.io/en/latest/omics/citeseq.html
# dsb https://muon.readthedocs.io/en/latest/api/generated/muon.prot.pp.dsb.html
# clr https://muon.readthedocs.io/en/latest/api/generated/muon.prot.pp.clr.html
normalisation_methods: clr

# CLR parameters:
# margin determines whether you normalise per cell (as you would RNA norm), 
# or by feature (recommended, due to the variable nature of adts). 
# CLR margin 0 is recommended for informative qc plots in this pipeline
# 0 = normalise colwise (per feature)
# 1 = normalise rowwise (per cell)
clr_margin: 0


# DSB parameters:
# quantile clipping, even with normalisation, 
# some cells get extreme outliers which can be clipped as discussed https://github.com/niaid/dsb
# maximum value will be set at the value of the 99.5% quantile, applied per feature
# note that this feature is in the default muon mu.pp.dsb code, but manually implemented in this code.
quantile_clipping: True
# in order to run DSB you must have access to the complete raw counts, including the empty droplets 
# from both rna and protein assays, 
# see details for how to make sure your files are compatible in the assess background section below




# ------------
# ATAC qc 
# ------------

# we require initializing one csv file per aggregated ATAC/multiome experiment.
# if you need to analyse multiple samples in the same project, aggregate them with the cellranger arc pipeline
# for multiome samples we recommend, specifying the 10X h5 input "10x_h5"
# per_barcode_metric is only avail on cellranger arc (multiome)

#is this an ATAC alone or a multiome sample?
is_paired: True
#this is NOT a multiome exp, but you have an RNA anndata that you would like to use for TSS enrichment, 
#leave empty if no rna provided
partner_rna: 
#if this is a standalone atac (is_paired: False), please provide a feature file to run TSS enrichment.
#supported annotations for protein coding genes provided
features_tss: #resources/features_tss_hg19.tsv
#these will be used to plot and saved in the metadata
# all metrics should be inputted as a comma separated string e.g. a,b,c
plotqc_atac_metrics: n_genes_by_counts,total_counts,pct_fragments_in_peaks,atac_peak_region_fragments,atac_mitochondrial_reads,atac_TSS_fragments


# ------------
# Repertoire QC
# ------------
# Repertoire data will be stored in one modality called "rep", if you provide both TCR and BCR data then this will be merged, 
# but various functions will be fun on TCR and BCR separately
# Review scirpy documentation for specifics of data storage https://scverse.org/scirpy/latest/index.html

# compute sequence distance metric (required for clonotype definition)
# for more info on the following args go to 
# https://scverse.org/scirpy/latest/generated/scirpy.pp.ir_dist.html#scirpy.pp.ir_dist
# leave blank for defaults
ir_dist:
  metric:
  sequence:

# clonotype definition 
# for more info on the following args go to 
# https://scverse.org/scirpy/latest/generated/scirpy.tl.define_clonotypes.html#scirpy.tl.define_clonotypes
# leave blank for defaults
clonotype_definition:
  receptor_arms:
  dual_ir:
  within_group:

# available metrics
# rep:clone_id_size
# rep:clonal_expansion
# rep:receptor_type
# rep:receptor_subtype
# rep:chain_pairing
# rep:multi_chain
# rep:high_confidence
# rep:is_cell
# rep:extra_chains
plotqc_rep_metrics:
 - is_cell
 - extra_chains
 - clonal_expansion
 - rep:receptor_type
 - rep:receptor_subtype
 - rep:chain_pairing
 - rep:multi_chain

  
# ------------
# Profiling Protein Ambient background
# ------------
# It is useful to chararcterise the background of your gene expression assay and antibody binding assay
# Inspect the plots and decide if to apply corrections, for example see Cellbender or SoupX.
# Please note that this analysis only makes sense if you are providing a RAW input (so the "empty" droplets can be used to
# estimate the BG )
# Setting `assess_background` to True will:
# 1. create h5mu from raw data inputs (expected as cellranger h5 or mtx folder, if you do not have this then set to False)
# 2. Plot comparitive QC plots to compare distribution of UMI and feature counts in background and foreground
# 3. Create heatmaps of the top features in the background, so you can compare teh background contaimation per channel
assess_background: False
# typically there is a lot of cells in the full raw cellranger outputs, 
# since we just want to get a picture of the background then we can subsample the data 
# to a more reasonable ize. If you want to keep all the raw data then set the following to False
downsample_background: True

# Files required for profiling ambient background or running dsb normalisation:
# -----------------------------------------------------
# the raw_feature_bc_matrix folder from cellranger or equivalent.
# The pipeline will automatically look for this as a .h5 or matrix folder 
# if the {mod}_filetype is set to "cellranger" or "cellranger_multi" or 10X_h5 
# based on the path specified in the submission file.

# If you are using a different format of file input e.g. csv matrix, 
# make sure the two files are named using the convention:
# {file_prefix}_filtered.csv" and {file_prefix}_raw.csv
