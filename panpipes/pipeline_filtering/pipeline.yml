# Pipeline pipeline_integration.py configuration file
# ==============================================

# compute resource options
# ------------------------
resources:
  # Number of threads used for parallel jobs
  threads_high: 4
  # nothing uses this atm.
  threads_low: 1


# allows for tweaking where the jobs get submitted, in case there is a special queue for long jobs or you have access to a gpu
# leave as is if you do not want to use the alternative queues
# also rescomp users need to request gpu access.

# Start
# --------------------------
# either one that exists already with
#tenx_dir:
#create_anndata: False
sample_prefix: 
unfiltered_obj: 
# if running this on prefiltered datat then
#1. set unfiltered obj (above) to blank
#2. rename your filtered file to match, the format PARAMS['sample_prefix'] + '_filt.h5ad'
#3. put renamed file in the same folder as this yml.

#TO DO this needs to go i think it doesn't make sense to save this file.

# leave empty if you don't want to save an intermediate muData with normalized expression 
# stored in X for the RNA object
output_logged_mudata:

modalities:
  rna:  
  prot: 
  rep: 
  atac: 

# Filtering
# --------------------------
filtering:
  run: True
  # a file containing only barcodes you want to keep, leave blank if not applicable
  keep_barcodes:
  #------------------------------------------------------
  rna:
  #------------------------------------------------------
    ## obs filtering: cell level filtering here
    obs:
      min:
        n_genes_by_counts: 
      max:
        total_counts: 
        n_genes_by_counts: 
        # percent filtering: 
        # this should be a value between 0 and 100%. 
        # leave blank or set to 100 to avoid filtering for any of these param
        pct_counts_mito: 
        pct_counts_ribo:
        # either one score for all samples e.g. 0.25, 
        # or a csv file with two columns sample_id, and cut off
        # less than
        scrublet_threshold:
    ## var filtering: (feature) gene level filtering here
    var:
      min:
        n_cells_by_counts: 
      max:
        total_counts:
        n_cells_by_counts:
  #------------------------------------------------------
  prot:
  #------------------------------------------------------
    ## obs filtering: cell level filtering here
    obs:  
      max:
        total_counts:
    ##var filtering: (feature) protein level filtering here
    var:
      max:
      min:
  #------------------------------------------------------
  atac:
  #------------------------------------------------------
    ## obs filtering: cell level filtering here
    obs:  
      max:
    ## var filtering: (feature) fragment level filtering here
    var:    
      nucleosome_signal:

# keep only the intersection of specific modalities e.g. rna,prot
intersect_mods: 


# ------------
# downsampling
# ------------
# how many cells to downsample to, leave blank to keep all cells.
downsample_n: 
# if we want to equalise by dataset or sample_id then specifiy a column in obs
# then the data will be subset to n cells **per** downsample_col value.
downsample_col: 
#  which modalities do we want to subsample
# comma separated string e.g. rna,prot
# if more than 1 modality is added then these will be intersected.
downsample_mods: 

# ------------
## plotting vars
# ------------
plotqc:
  # use these categorical variables to plot/split by and count the cells
  grouping_var: sample_id,tissue,patient,channel
  # use these continuous variables to plot gradients and distributions
  metrics: pct_counts_mt,pct_counts_rp,pct_counts_hb,pct_counts_ig,doublet_scores


# Normalisation
# --------------------------
# hvg_flavour options include "seurat", "cell_ranger", "seurat_v3", default; "seurat"
# for dispersion based methods "seurat" and "cell_ranger", you can specify parameters: min_mean, max_mean, min_disp
# for "seurat_v3" a different method is used, a you specify how many variavle genes to find.
# If you specify n_top_genes, then the other paramteres are nulled.
# details: https://scanpy.readthedocs.io/en/stable/api/scanpy.pp.highly_variable_genes.html
hvg:
  # there is a defaul exclusions file for immune cells in sc_pipelines/resources/exclude_genes_HLAIGTR_v1.txt
  # examine this to see what format is expected, if you want to use this file set the parameter to "default
  exclude: default
  flavor: seurat_v3 # "seurat", "cell_ranger", "seurat_v3"
  n_top_genes: 2000
  min_mean:
  max_mean:
  min_disp:
  # if you want to filter the scaled object by hvgs (essential for large datasets) then set filter to True
  filter: False

# Regression variables, what do you want to regress out, leave blank if nothing
# I recommend not regressing out unless you have good reason to.
regress_variables:

# scale, clip values as per: https://scanpy.readthedocs.io/en/stable/api/scanpy.pp.scale.html
# generally leave
scale_max_value:

# run pca upstream correction methods.  
pca:
  scree_n_pcs: 50
  color_by: sample_id

adt:
  normalisation_methods: clr,dsb
  clr_margin: 0
  quantile_clipping: True
raw_obj:
#
atac:
  binarize: False
  normalize: TFIDF
  TFIDF_flavour: signac
  # leave the below blank to use defaults
  min_mean:
  max_mean:
  min_disp:
  lsi_remove: 1,4,6